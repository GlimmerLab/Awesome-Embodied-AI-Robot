import os
import re
import json
import requests
import arxiv
from datetime import datetime
from bs4 import BeautifulSoup
from tqdm import tqdm
import string

class PaperUpdater:
    def __init__(self):
        self.base_url = "https://arxiv.paperswithcode.com/api/v0/papers/"
        # å®šä¹‰ç›®å½•å’Œå¯¹åº”çš„æ£€ç´¢å…³é”®è¯
        self.categories = {
            "Motion-Planning": "motion planning OR trajectory optimization OR path planning OR collision avoidance OR whole-body motion OR dynamic motion OR real-time planning OR humanoid control OR robot control OR locomotion planning",
            "Task-Planning": "task planning OR task decomposition OR task scheduling OR hierarchical planning OR TAMP OR task and motion planning OR learning-based planning OR multi-agent planning OR long-horizon planning OR semantic planning",
            "Simulation-Platforms": "physics engine OR robot simulation OR simulation environment OR digital twin OR synthetic data OR benchmark platform OR physics simulator OR virtual environment OR robot environment OR learning environment",
            "Robot-Learning-and-Reinforcement-Learning": "reinforcement learning OR RL OR policy learning OR robot learning OR legged robot OR quadruped OR biped OR locomotion OR motor skill OR imitation learning OR policy gradient OR PPO OR SAC OR DDPG OR sim2real OR transfer learning OR multi-task learning OR hierarchical RL OR meta-learning OR offline RL",
            "Multimodal-Interaction": "multimodal OR multi-modal OR cross-modal OR human-robot interaction OR vision language OR visual language OR gesture recognition OR speech interaction OR tactile interaction OR social robotics OR natural language for robots OR robot reasoning OR embodied interaction OR embodied communication",
            "Environment-Perception": "environment perception OR scene understanding OR object detection OR visual perception OR terrain understanding OR SLAM OR mapping OR sensor fusion OR 3D perception OR semantic segmentation OR depth estimation OR point cloud processing OR visual navigation OR visual localization",
            "Fundamental-Theory": "embodied AI OR embodied intelligence OR embodied learning OR cognitive science OR control theory OR embodied cognition OR computational models OR learning theory OR evaluation methods OR embodied representation OR embodied generalization OR embodied reasoning OR embodied memory OR embodied adaptation"
        }

        # åˆå§‹åŒ–æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡å­—å…¸
        self.manually_added_papers = {}

        # å®šä¹‰å„ä¸»é¢˜çš„æ ‡ç­¾å’Œå…³é”®è¯
        self.tags = {
            # å¼ºåŒ–å­¦ä¹ æ ‡ç­¾
            "Robot-Learning-and-Reinforcement-Learning": {
                "Foundational": ["foundational", "fundamental", "core", "basic", "essential", "pioneering", "seminal"],
                "Imitation": ["imitation", "demonstration", "expert", "teacher", "learning from demonstration", "behavioral cloning", "apprenticeship learning"],
                "Milestone": ["milestone", "breakthrough", "significant", "important", "key", "landmark", "pivotal"],
                "Biped": ["biped", "bipedal", "humanoid", "two-legged", "walking", "running", "jumping"],
                "Quadruped": ["quadruped", "four-legged", "dog", "animal", "canine", "feline", "mammal"],
                "AMP": ["AMP", "adversarial", "motion prior", "style", "character", "motion style", "motion imitation"],
                "Adaptation": ["adaptation", "transfer", "generalization", "robust", "resilient", "domain adaptation", "zero-shot", "few-shot"],
                "Policy": ["policy", "actor-critic", "PPO", "SAC", "DDPG", "TRPO", "policy optimization", "policy gradient", "value function"],
                "Sim2Real": ["sim2real", "sim-to-real", "transfer", "domain", "reality gap", "simulation transfer", "simulation adaptation", "reality gap"],
                "Hierarchical": ["hierarchical", "HRL", "option", "skill", "subgoal", "hierarchical RL", "option discovery", "skill discovery"],
                "Multi-Task": ["multi-task", "multi-task learning", "generalist", "versatile", "multi-task RL", "task generalization", "task transfer"],
                "Offline": ["offline", "batch", "off-policy", "data-driven", "offline RL", "batch RL", "conservative RL", "data-efficient"],
                "Meta": ["meta", "meta-learning", "few-shot", "adaptation", "meta-RL", "model-agnostic meta-learning", "reptile", "maml"],
                "Multi-Agent": ["multi-agent", "collaboration", "cooperation", "interaction", "multi-agent RL", "team learning", "collective intelligence"]
            },
            # è¿åŠ¨è§„åˆ’æ ‡ç­¾
            "Motion-Planning": {
                "Trajectory": ["trajectory", "path", "motion", "planning", "optimization", "trajectory optimization", "path planning", "motion planning", "trajectory generation"],
                "Collision": ["collision", "avoidance", "safety", "obstacle", "collision avoidance", "obstacle avoidance", "safety constraints", "collision-free"],
                "Real-time": ["real-time", "realtime", "fast", "efficient", "computational", "real-time planning", "fast planning", "efficient planning", "computational efficiency"],
                "Learning": ["learning", "learned", "neural", "deep", "ML", "learning-based planning", "neural planning", "deep planning", "ML-based planning"],
                "Dynamic": ["dynamic", "dynamics", "kinematic", "kinematics", "dynamic planning", "dynamics-aware", "kinematic planning", "dynamic constraints"],
                "Uncertainty": ["uncertainty", "robust", "stochastic", "probabilistic", "uncertainty-aware", "robust planning", "stochastic planning", "probabilistic planning"],
                "Multi-robot": ["multi-robot", "swarm", "collaborative", "coordination", "multi-robot planning", "swarm planning", "collaborative planning", "coordinated planning"],
                "Reactive": ["reactive", "reaction", "responsive", "adaptive", "reactive planning", "reactive control", "responsive planning", "adaptive planning"],
                "Whole-body": ["whole-body", "full-body", "whole-body planning", "full-body planning", "whole-body motion", "full-body motion", "whole-body control"],
                "Humanoid": ["humanoid", "humanoid planning", "humanoid control", "humanoid motion", "humanoid locomotion", "humanoid walking", "humanoid running"]
            },
            # ä»»åŠ¡è§„åˆ’æ ‡ç­¾
            "Task-Planning": {
                "Hierarchical": ["hierarchical", "hierarchy", "decomposition", "subtask", "hierarchical planning", "task decomposition", "subtask planning", "hierarchical task"],
                "Temporal": ["temporal", "temporal logic", "sequence", "ordering", "temporal planning", "sequence planning", "temporal constraints", "temporal reasoning"],
                "Learning": ["learning", "learned", "neural", "deep", "ML", "learning-based planning", "neural planning", "deep planning", "ML-based planning"],
                "Semantic": ["semantic", "language", "instruction", "command", "semantic planning", "language-based planning", "instruction-based planning", "command-based planning"],
                "Multi-agent": ["multi-agent", "collaboration", "cooperation", "interaction", "multi-agent planning", "collaborative planning", "cooperative planning", "team planning"],
                "Uncertainty": ["uncertainty", "robust", "stochastic", "probabilistic", "uncertainty-aware", "robust planning", "stochastic planning", "probabilistic planning"],
                "Interactive": ["interactive", "human", "user", "feedback", "interactive planning", "human-in-the-loop", "user feedback", "interactive learning"],
                "Long-horizon": ["long-horizon", "long-term", "complex", "sequential", "long-horizon planning", "long-term planning", "complex task", "sequential task"],
                "TAMP": ["TAMP", "task and motion planning", "integrated planning", "combined planning", "task-motion", "task-motion integration", "task-motion coordination"],
                "Reasoning": ["reasoning", "logical", "symbolic", "abstract", "task reasoning", "logical planning", "symbolic planning", "abstract reasoning"]
            },
            # ä»¿çœŸå¹³å°æ ‡ç­¾
            "Simulation-Platforms": {
                "Physics": ["physics", "engine", "simulation", "dynamics", "physics engine", "physics simulator", "dynamics simulation", "physical simulation"],
                "Visual": ["visual", "rendering", "graphics", "3D", "visualization", "renderer", "visual simulation", "3D rendering", "graphics engine"],
                "Realistic": ["realistic", "realism", "photo-realistic", "high-fidelity", "realistic simulation", "photo-realism", "high-fidelity simulation", "realistic rendering"],
                "Benchmark": ["benchmark", "evaluation", "test", "challenge", "benchmarking platform", "evaluation framework", "testing framework", "challenge platform"],
                "Multi-domain": ["multi-domain", "multi-task", "versatile", "general", "multi-robot", "multi-domain simulation", "multi-task environment", "versatile platform"],
                "Open-source": ["open-source", "open source", "community", "collaborative", "public", "open-source platform", "community-driven", "collaborative development"],
                "Scalable": ["scalable", "parallel", "distributed", "efficient", "high-performance", "scalable simulation", "parallel simulation", "distributed simulation"],
                "Interactive": ["interactive", "user", "human", "interface", "interaction", "interactive simulation", "user interface", "human interaction", "interactive environment"],
                "Digital Twin": ["digital twin", "virtual world", "virtual environment", "synthetic environment", "digital representation", "virtual representation", "synthetic world"],
                "Robot Environment": ["robot environment", "robot simulation", "robot simulator", "robot platform", "robot testbed", "robot testing", "robot evaluation", "robot development"],
                "Learning Environment": ["learning environment", "training environment", "simulation environment", "testbed", "learning platform", "training platform", "simulation testbed", "learning testbed"]
            },
            # å¤šæ¨¡æ€äº¤äº’æ ‡ç­¾
            "Multimodal-Interaction": {
                "Vision-Language": ["vision-language", "visual language", "image-text", "multimodal", "vision-language model", "visual language model", "image-text model", "multimodal model"],
                "Human-Robot": ["human-robot", "human robot", "interaction", "collaboration", "human-robot interaction", "human-robot collaboration", "human-robot communication", "human-robot cooperation"],
                "Gesture": ["gesture", "motion", "body", "sign", "gesture recognition", "body language", "sign language", "motion understanding", "gesture understanding"],
                "Speech": ["speech", "audio", "voice", "sound", "speech recognition", "audio processing", "voice interaction", "sound understanding", "speech understanding"],
                "Tactile": ["tactile", "touch", "haptic", "force", "tactile sensing", "touch sensing", "haptic feedback", "force sensing", "tactile interaction"],
                "Learning": ["learning", "learned", "neural", "deep", "ML", "multimodal learning", "cross-modal learning", "fusion learning", "joint learning"],
                "Real-time": ["real-time", "realtime", "fast", "efficient", "real-time interaction", "fast response", "efficient processing", "real-time processing"],
                "Social": ["social", "emotional", "cognitive", "mental", "social robotics", "emotional intelligence", "cognitive interaction", "mental model", "social understanding"],
                "Natural Language": ["natural language", "language understanding", "language generation", "language model", "NLP", "language processing", "language interaction", "language communication"],
                "Embodied": ["embodied", "embodiment", "physical", "corporeal", "embodied interaction", "physical interaction", "corporeal communication", "embodied communication"]
            },
            # ç¯å¢ƒæ„ŸçŸ¥æ ‡ç­¾
            "Environment-Perception": {
                "Object": ["object", "detection", "recognition", "tracking", "object detection", "object recognition", "object tracking", "object understanding", "object localization"],
                "Scene": ["scene", "understanding", "parsing", "segmentation", "scene understanding", "scene parsing", "scene segmentation", "scene recognition", "scene analysis"],
                "3D": ["3D", "point cloud", "depth", "stereo", "3D perception", "point cloud processing", "depth estimation", "stereo vision", "3D reconstruction"],
                "Semantic": ["semantic", "meaning", "interpretation", "reasoning", "semantic understanding", "semantic interpretation", "semantic reasoning", "semantic analysis", "semantic mapping"],
                "Learning": ["learning", "learned", "neural", "deep", "ML", "perception learning", "visual learning", "sensor learning", "environment learning"],
                "Real-time": ["real-time", "realtime", "fast", "efficient", "real-time perception", "fast perception", "efficient perception", "real-time processing"],
                "Robust": ["robust", "robustness", "adversarial", "attack", "robust perception", "adversarial robustness", "attack resistance", "robust recognition"],
                "Multi-modal": ["multi-modal", "multimodal", "fusion", "integration", "multi-modal perception", "sensor fusion", "modality integration", "cross-modal perception"],
                "SLAM": ["SLAM", "mapping", "localization", "navigation", "simultaneous localization and mapping", "environment mapping", "robot localization", "visual navigation"],
                "Terrain": ["terrain", "ground", "surface", "environment", "terrain understanding", "ground perception", "surface analysis", "environment analysis"]
            },
            # åŸºç¡€ç†è®ºæ ‡ç­¾
            "Fundamental-Theory": {
                "Cognitive": ["cognitive", "cognition", "mental", "brain", "cognitive science", "cognitive model", "mental representation", "brain-inspired", "cognitive architecture"],
                "Control": ["control", "controller", "stability", "dynamics", "control theory", "controller design", "stability analysis", "dynamics modeling", "control architecture"],
                "Learning": ["learning", "learned", "neural", "deep", "ML", "learning theory", "neural learning", "deep learning", "machine learning", "representation learning"],
                "Representation": ["representation", "embedding", "feature", "latent", "representation learning", "embedding space", "feature learning", "latent space", "concept learning"],
                "Generalization": ["generalization", "transfer", "adaptation", "robust", "generalization theory", "transfer learning", "adaptation mechanism", "robust learning", "domain generalization"],
                "Theory": ["theory", "theoretical", "analysis", "proof", "theoretical framework", "theoretical analysis", "mathematical proof", "theoretical model", "theoretical foundation"],
                "Survey": ["survey", "review", "overview", "tutorial", "literature survey", "research review", "field overview", "comprehensive tutorial", "state-of-the-art review"],
                "Benchmark": ["benchmark", "evaluation", "test", "challenge", "benchmarking framework", "evaluation methodology", "testing framework", "challenge design", "performance metrics"],
                "Embodied": ["embodied", "embodiment", "physical", "corporeal", "embodied intelligence", "embodied cognition", "physical intelligence", "corporeal learning", "embodied learning"],
                "Reasoning": ["reasoning", "inference", "logic", "abstract", "reasoning mechanism", "inference engine", "logical reasoning", "abstract thinking", "reasoning model"]
            }
        }

        self.existing_papers = self.load_existing_papers()
        self.keywords = self.extract_keywords_from_existing_papers()

    def ensure_directory_exists(self, directory):
        """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"åˆ›å»ºç›®å½•: {directory}")

    def load_existing_papers(self):
        """åŠ è½½ç°æœ‰è®ºæ–‡ä¿¡æ¯"""
        existing_papers = {}
        for category in self.categories.keys():
            existing_papers[category] = []
            en_file = f"{category}/README.md"
            cn_file = f"{category}/README_CN.md"

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.ensure_directory_exists(category)

            if os.path.exists(en_file):
                with open(en_file, "r", encoding="utf-8") as f:
                    content = f.read()

                    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡å—
                    manual_papers_match = re.search(r'## Manually Added Papers\n\n(.*?)(?=\n## |$)', content, re.DOTALL)
                    if manual_papers_match:
                        manual_papers_content = manual_papers_match.group(1)
                        # æå–æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡ä¿¡æ¯
                        manual_table_rows = re.findall(r'\|(.*?)\|(.*?)\|(.*?)\|(.*?)\|(.*?)\|', manual_papers_content)
                        for row in manual_table_rows:
                            # è·³è¿‡è¡¨å¤´è¡Œ
                            if row[0].strip() == "Date" or row[0].strip() == "æ—¥æœŸ":
                                continue
                            if row[0].strip() == ":---:":
                                continue

                            date, title, pdf_link, code_link, rating = row
                            # æå–PDFé“¾æ¥
                            pdf_url_match = re.search(r'\[\[pdf\]\]\((.*?)\)', pdf_link)
                            pdf_url = pdf_url_match.group(1) if pdf_url_match else pdf_link

                            # æå–ä»£ç é“¾æ¥
                            code_url_match = re.search(r'\[(.*?)\]\((.*?)\)', code_link)
                            if code_url_match:
                                code_url = code_url_match.group(2)
                            else:
                                code_url = code_url_match.group(0) if code_url_match else code_link.strip()

                            # æ¸…ç†æ ‡é¢˜
                            clean_title = title.strip()

                            paper_info = {
                                "date": date.strip(),
                                "title": clean_title,
                                "pdf_url": pdf_url,
                                "code_url": code_url,
                                "rating": rating.strip(),
                                "manual": True  # æ ‡è®°ä¸ºæ‰‹åŠ¨æ·»åŠ 
                            }
                            existing_papers[category].append(paper_info)

                            # å°†æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡ä¿å­˜åˆ°manually_added_paperså­—å…¸ä¸­
                            if category not in self.manually_added_papers:
                                self.manually_added_papers[category] = []
                            self.manually_added_papers[category].append(paper_info)

                    # æå–è‡ªåŠ¨æ›´æ–°çš„è®ºæ–‡ä¿¡æ¯
                    auto_papers_match = re.search(r'## Auto-Updated Papers\n\n(.*?)(?=\n## |$)', content, re.DOTALL)
                    if auto_papers_match:
                        auto_papers_content = auto_papers_match.group(1)
                        table_rows = re.findall(r'\|(.*?)\|(.*?)\|(.*?)\|(.*?)\|(.*?)\|', auto_papers_content)
                        for row in table_rows:
                            # è·³è¿‡è¡¨å¤´è¡Œ
                            if row[0].strip() == "Date" or row[0].strip() == "æ—¥æœŸ":
                                continue
                            if row[0].strip() == ":---:":
                                continue

                            date, title, pdf_link, code_link, rating = row
                            # æå–PDFé“¾æ¥
                            pdf_url_match = re.search(r'\[\[pdf\]\]\((.*?)\)', pdf_link)
                            pdf_url = pdf_url_match.group(1) if pdf_url_match else pdf_link

                            # æå–ä»£ç é“¾æ¥
                            code_url_match = re.search(r'\[(.*?)\]\((.*?)\)', code_link)
                            if code_url_match:
                                code_url = code_url_match.group(2)
                            else:
                                code_url = code_url_match.group(0) if code_url_match else code_link.strip()

                            # æ¸…ç†æ ‡é¢˜
                            clean_title = title.strip()

                            existing_papers[category].append({
                                "date": date.strip(),
                                "title": clean_title,
                                "pdf_url": pdf_url,
                                "code_url": code_url,
                                "rating": rating.strip(),
                                "manual": False  # æ ‡è®°ä¸ºè‡ªåŠ¨æ›´æ–°
                            })

        return existing_papers

    def extract_keywords_from_existing_papers(self):
        """ä»ç°æœ‰è®ºæ–‡æ ‡é¢˜ä¸­æå–å…³é”®è¯"""
        keywords = {}
        for category, papers in self.existing_papers.items():
            if not papers:
                keywords[category] = self.categories[category]
                continue

            # æ”¶é›†æ‰€æœ‰æ ‡é¢˜
            titles = [paper["title"] for paper in papers]

            # ç®€å•åˆ†è¯å¹¶æå–å…³é”®è¯
            all_words = []
            for title in titles:
                # ç®€å•çš„åˆ†è¯æ–¹æ³•ï¼ŒæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·åˆ†å‰²
                words = re.findall(r'\b\w+\b', title.lower())
                # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¯
                words = [word for word in words if len(word) > 3]
                all_words.extend(words)

            # ç»Ÿè®¡è¯é¢‘
            word_freq = {}
            for word in all_words:
                if word in word_freq:
                    word_freq[word] += 1
                else:
                    word_freq[word] = 1

            # é€‰æ‹©æœ€å¸¸è§çš„è¯ä½œä¸ºå…³é”®è¯
            top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
            keyword_query = " OR ".join([word for word, _ in top_words])

            # ç»“åˆåŸå§‹æŸ¥è¯¢å’Œæå–çš„å…³é”®è¯
            keywords[category] = f"({self.categories[category]}) AND ({keyword_query})"

        return keywords

    def get_paper_info(self, paper_id):
        """è·å–è®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä»£ç é“¾æ¥"""
        try:
            code_url = self.base_url + paper_id
            response = requests.get(code_url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if "official" in data and "url" in data["official"]:
                    return data["official"]["url"]
            return None
        except:
            return None

    def identify_tag(self, category, title, abstract):
        """è¯†åˆ«è®ºæ–‡çš„æ ‡ç­¾"""
        # ä¸å†ä½¿ç”¨æ ‡ç­¾ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    def get_daily_papers(self, category, query, max_results=50):
        """è·å–æ¯æ—¥è®ºæ–‡"""
        papers = []
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate
        )

        for result in tqdm(search.results(), desc=f"è·å–{category}è®ºæ–‡"):
            paper_id = result.get_short_id()

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if any(paper["title"] == result.title for paper in self.existing_papers[category]):
                continue

            code_url = self.get_paper_info(paper_id)

            # å°è¯•è¯†åˆ«æ ‡ç­¾
            title = result.title
            tag = self.identify_tag(category, title, result.summary)

            # å¦‚æœæ ‡é¢˜ä¸­æœ‰å†’å·ï¼Œå°è¯•æå–æ ‡ç­¾
            if not tag and ":" in title:
                tag = title.split(":")[0].strip()
                title = title.split(":")[1].strip()

            paper_info = {
                "date": str(result.published.date()),
                "title": title,
                "tag": tag,
                "authors": [author.name for author in result.authors],
                "abstract": result.summary,
                "pdf_url": result.entry_id,
                "code_url": code_url if code_url else "âš ï¸",
                "rating": "â­ï¸â­ï¸â­ï¸",  # é»˜è®¤è¯„åˆ†
                "has_code": code_url is not None,
                "manual": False  # æ ‡è®°ä¸ºè‡ªåŠ¨æ›´æ–°
            }
            papers.append(paper_info)

        return papers

    def update_category_readme(self, category, new_papers):
        """æ›´æ–°åˆ†ç±»ç›®å½•çš„READMEæ–‡ä»¶"""
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.ensure_directory_exists(category)

        # è·å–ç°æœ‰çš„æ‰‹åŠ¨æ·»åŠ è®ºæ–‡
        existing_manual_papers = self.manually_added_papers.get(category, [])

        # è¿‡æ»¤æ‰å·²ç»å­˜åœ¨äºæ‰‹åŠ¨æ·»åŠ è®ºæ–‡ä¸­çš„æ–°è®ºæ–‡
        filtered_new_papers = []
        for paper in new_papers:
            if not any(p['title'] == paper['title'] for p in existing_manual_papers):
                filtered_new_papers.append(paper)

        # åˆå¹¶æ‰€æœ‰è‡ªåŠ¨æ›´æ–°çš„è®ºæ–‡
        all_auto_papers = filtered_new_papers

        # æŒ‰æ—¥æœŸæ’åº
        existing_manual_papers.sort(key=lambda x: x['date'], reverse=True)
        all_auto_papers.sort(key=lambda x: x['date'], reverse=True)

        # å®šä¹‰å„ä¸»é¢˜çš„ç®€ä»‹å’Œä¸»è¦å†…å®¹
        category_intros = {
            "Motion-Planning": {
                "en": "This directory collects papers and code implementations related to motion planning in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸è¿åŠ¨è§„åˆ’ç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            },
            "Task-Planning": {
                "en": "This directory collects papers and code implementations related to task planning in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸ä»»åŠ¡è§„åˆ’ç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            },
            "Simulation-Platforms": {
                "en": "This directory collects papers and code implementations related to simulation platforms in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸ä»¿çœŸå¹³å°ç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            },
            "Robot-Learning-and-Reinforcement-Learning": {
                "en": "This directory collects papers and code implementations related to robot learning and reinforcement learning in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸æœºå™¨äººå­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            },
            "Multimodal-Interaction": {
                "en": "This directory collects papers and code implementations related to multimodal interaction in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸å¤šæ¨¡æ€äº¤äº’ç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            },
            "Environment-Perception": {
                "en": "This directory collects papers and code implementations related to environment perception in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸ç¯å¢ƒæ„ŸçŸ¥ç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            },
            "Fundamental-Theory": {
                "en": "This directory collects papers and code implementations related to fundamental theory in embodied AI.",
                "cn": "æœ¬ç›®å½•æ”¶é›†äº†å…·èº«æ™ºèƒ½ä¸­ä¸åŸºç¡€ç†è®ºç›¸å…³çš„è®ºæ–‡å’Œä»£ç å®ç°ã€‚"
            }
        }

        # å®šä¹‰å„ä¸»é¢˜çš„ä¸»è¦å†…å®¹
        category_contents = {
            "Motion-Planning": {
                "en": [
                    "Dynamic Motion Planning",
                    "Whole-Body Motion Planning",
                    "Trajectory Optimization",
                    "Collision Avoidance",
                    "Real-time Planning",
                    "Humanoid Robot Control"
                ],
                "cn": [
                    "åŠ¨æ€è¿åŠ¨è§„åˆ’",
                    "å…¨èº«è¿åŠ¨è§„åˆ’",
                    "è½¨è¿¹ä¼˜åŒ–",
                    "ç¢°æ’é¿å…",
                    "å®æ—¶è§„åˆ’",
                    "äººå½¢æœºå™¨äººæ§åˆ¶"
                ]
            },
            "Task-Planning": {
                "en": [
                    "High-level Task Planning",
                    "Hierarchical Planning",
                    "Task and Motion Planning (TAMP)",
                    "Learning-based Planning",
                    "Multi-agent Planning"
                ],
                "cn": [
                    "é«˜å±‚ä»»åŠ¡è§„åˆ’",
                    "åˆ†å±‚è§„åˆ’",
                    "ä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’(TAMP)",
                    "åŸºäºå­¦ä¹ çš„è§„åˆ’",
                    "å¤šæ™ºèƒ½ä½“è§„åˆ’"
                ]
            },
            "Simulation-Platforms": {
                "en": [
                    "Physics Simulators",
                    "Robot Simulation Environments",
                    "Learning Environments",
                    "Benchmarking Platforms",
                    "Digital Twins",
                    "Synthetic Data Generation"
                ],
                "cn": [
                    "ç‰©ç†ä»¿çœŸå™¨",
                    "æœºå™¨äººä»¿çœŸç¯å¢ƒ",
                    "å­¦ä¹ ç¯å¢ƒ",
                    "åŸºå‡†æµ‹è¯•å¹³å°",
                    "æ•°å­—å­ªç”Ÿ",
                    "åˆæˆæ•°æ®ç”Ÿæˆ"
                ]
            },
            "Robot-Learning-and-Reinforcement-Learning": {
                "en": [
                    "Foundational Works",
                    "Imitation Learning",
                    "Skill Learning",
                    "Multi-task and Transfer Learning",
                    "Advanced Policy Learning",
                    "Sim-to-Real Transfer",
                    "Cross-Morphology Learning"
                ],
                "cn": [
                    "å¥ åŸºæ€§å·¥ä½œ",
                    "æ¨¡ä»¿å­¦ä¹ ",
                    "æŠ€èƒ½å­¦ä¹ ",
                    "å¤šä»»åŠ¡ä¸è¿ç§»å­¦ä¹ ",
                    "é«˜çº§ç­–ç•¥å­¦ä¹ ",
                    "Sim-to-Realè¿ç§»",
                    "è·¨å½¢æ€å­¦ä¹ "
                ]
            },
            "Multimodal-Interaction": {
                "en": [
                    "Human-Robot Interaction",
                    "Natural Language Processing for Robots",
                    "Gesture Recognition and Understanding",
                    "Multi-modal Learning and Fusion",
                    "Social Robotics",
                    "Robot Reasoning and Memory"
                ],
                "cn": [
                    "äººæœºäº¤äº’",
                    "æœºå™¨äººè‡ªç„¶è¯­è¨€å¤„ç†",
                    "æ‰‹åŠ¿è¯†åˆ«ä¸ç†è§£",
                    "å¤šæ¨¡æ€å­¦ä¹ ä¸èåˆ",
                    "ç¤¾äº¤æœºå™¨äºº",
                    "æœºå™¨äººæ¨ç†ä¸è®°å¿†"
                ]
            },
            "Environment-Perception": {
                "en": [
                    "Visual Perception",
                    "Terrain Understanding",
                    "SLAM and Mapping",
                    "Scene Understanding",
                    "Sensor Fusion"
                ],
                "cn": [
                    "è§†è§‰æ„ŸçŸ¥",
                    "åœ°å½¢ç†è§£",
                    "SLAMä¸åœ°å›¾æ„å»º",
                    "åœºæ™¯ç†è§£",
                    "ä¼ æ„Ÿå™¨èåˆ"
                ]
            },
            "Fundamental-Theory": {
                "en": [
                    "Cognitive Foundations of Embodied Intelligence",
                    "Computational Models of Embodied Intelligence",
                    "Learning Theory in Embodied Intelligence",
                    "Evaluation Methods for Embodied Intelligence"
                ],
                "cn": [
                    "å…·èº«æ™ºèƒ½çš„è®¤çŸ¥åŸºç¡€",
                    "å…·èº«æ™ºèƒ½çš„è®¡ç®—æ¨¡å‹",
                    "å…·èº«æ™ºèƒ½çš„å­¦ä¹ ç†è®º",
                    "å…·èº«æ™ºèƒ½çš„è¯„ä¼°æ–¹æ³•"
                ]
            }
        }

        # ä¿®æ”¹ä»£ç é“¾æ¥æ ¼å¼
        def format_code_link(code_url):
            if code_url == "âš ï¸":
                return "âš ï¸"
            else:
                # æå–ä»£ç åç§°
                code_name = code_url.split("/")[-1].replace(")", "")
                # è¿”å›æ ‡å‡†çš„ Markdown é“¾æ¥æ ¼å¼
                return f"[{code_name}]({code_url})"

        # æ›´æ–°è‹±æ–‡README
        en_file = f"{category}/README.md"
        if os.path.exists(en_file):
            with open(en_file, "r", encoding="utf-8") as f:
                content = f.read()

                # æå–æ ‡é¢˜å’Œè¯­è¨€åˆ‡æ¢éƒ¨åˆ†
                title_match = re.match(r'(#.*?\n\n>.*?\n\n)', content, re.DOTALL)
                if title_match:
                    title_section = title_match.group(1)
                    en_content = f"{title_section}{category_intros[category]['en']}\n\n"
                    en_content += "## Main Contents\n\n"
                    for content in category_contents[category]['en']:
                        en_content += f"- {content}\n"
                    en_content += "\n"

                    # æ·»åŠ æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡
                    en_content += "## Manually Added Papers\n\n"
                    if existing_manual_papers:
                        en_content += "|Date|Title|Paper|Code|Rating|\n"
                        en_content += "|:---:|:---:|:---:|:---:|:---:|\n"
                        for paper in existing_manual_papers:
                            code_link = format_code_link(paper['code_url'])
                            en_content += f"|{paper['date']}|{paper['title']}|[[pdf]]({paper['pdf_url']})|{code_link}|{paper['rating']}|\n"
                    en_content += "\n"

                    # æ·»åŠ è‡ªåŠ¨æ›´æ–°çš„è®ºæ–‡
                    en_content += "## Auto-Updated Papers\n\n"
                    if all_auto_papers:
                        en_content += "|Date|Title|Paper|Code|Rating|\n"
                        en_content += "|:---:|:---:|:---:|:---:|:---:|\n"
                        for paper in all_auto_papers:
                            code_link = format_code_link(paper['code_url'])
                            en_content += f"|{paper['date']}|{paper['title']}|[[pdf]]({paper['pdf_url']})|{code_link}|{paper['rating']}|\n"
                    en_content += "\n"

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    total_papers = len(existing_manual_papers) + len(all_auto_papers)
                    code_implementations = sum(1 for p in existing_manual_papers + all_auto_papers if p['code_url'] != "âš ï¸")
                    en_content += "## ğŸ“Š Statistics\n\n"
                    en_content += f"- Total Papers: {total_papers}\n"
                    en_content += f"- Code Implementations: {code_implementations}\n"
                    en_content += f"- Last Updated: {datetime.now().strftime('%B %Y')}\n"

                    # å†™å…¥è‹±æ–‡README
                    with open(en_file, "w", encoding="utf-8") as f:
                        f.write(en_content)

        # æ›´æ–°ä¸­æ–‡README
        cn_file = f"{category}/README_CN.md"
        if os.path.exists(cn_file):
            with open(cn_file, "r", encoding="utf-8") as f:
                content = f.read()

                # æå–æ ‡é¢˜å’Œè¯­è¨€åˆ‡æ¢éƒ¨åˆ†
                title_match = re.match(r'(#.*?\n\n>.*?\n\n)', content, re.DOTALL)
                if title_match:
                    title_section = title_match.group(1)
                    cn_content = f"{title_section}{category_intros[category]['cn']}\n\n"
                    cn_content += "## ä¸»è¦å†…å®¹\n\n"
                    for content in category_contents[category]['cn']:
                        cn_content += f"- {content}\n"
                    cn_content += "\n"

                    # æ·»åŠ æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡
                    cn_content += "## æ‰‹åŠ¨æ·»åŠ çš„è®ºæ–‡\n\n"
                    if existing_manual_papers:
                        cn_content += "|æ—¥æœŸ|æ ‡é¢˜|è®ºæ–‡|ä»£ç |æ¨èæŒ‡æ•°|\n"
                        cn_content += "|:---:|:---:|:---:|:---:|:---:|\n"
                        for paper in existing_manual_papers:
                            code_link = format_code_link(paper['code_url'])
                            cn_content += f"|{paper['date']}|{paper['title']}|[[pdf]]({paper['pdf_url']})|{code_link}|{paper['rating']}|\n"
                    cn_content += "\n"

                    # æ·»åŠ è‡ªåŠ¨æ›´æ–°çš„è®ºæ–‡
                    cn_content += "## è‡ªåŠ¨æ›´æ–°çš„è®ºæ–‡\n\n"
                    if all_auto_papers:
                        cn_content += "|æ—¥æœŸ|æ ‡é¢˜|è®ºæ–‡|ä»£ç |æ¨èæŒ‡æ•°|\n"
                        cn_content += "|:---:|:---:|:---:|:---:|:---:|\n"
                        for paper in all_auto_papers:
                            code_link = format_code_link(paper['code_url'])
                            cn_content += f"|{paper['date']}|{paper['title']}|[[pdf]]({paper['pdf_url']})|{code_link}|{paper['rating']}|\n"
                    cn_content += "\n"

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    total_papers = len(existing_manual_papers) + len(all_auto_papers)
                    code_implementations = sum(1 for p in existing_manual_papers + all_auto_papers if p['code_url'] != "âš ï¸")
                    cn_content += "## ğŸ“Š ç»Ÿè®¡\n\n"
                    cn_content += f"- è®ºæ–‡æ€»æ•°ï¼š{total_papers}ç¯‡\n"
                    cn_content += f"- ä»£ç å®ç°ï¼š{code_implementations}ä¸ª\n"
                    cn_content += f"- æœ€åæ›´æ–°ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ')}\n"

                    # å†™å…¥ä¸­æ–‡README
                    with open(cn_file, "w", encoding="utf-8") as f:
                        f.write(cn_content)

        # æ›´æ–°ç°æœ‰è®ºæ–‡åˆ—è¡¨
        self.existing_papers[category] = existing_manual_papers + all_auto_papers

    def update_root_readme(self):
        """æ›´æ–°æ ¹ç›®å½•çš„READMEæ–‡ä»¶"""
        total_papers = 0
        total_codes = 0

        # ç»Ÿè®¡æ‰€æœ‰åˆ†ç±»çš„è®ºæ–‡å’Œä»£ç æ•°é‡
        for category in self.categories.keys():
            if os.path.exists(f"{category}/README.md"):
                with open(f"{category}/README.md", "r", encoding="utf-8") as f:
                    content = f.read()
                    # è®¡ç®—è®ºæ–‡æ•°é‡ï¼ˆå‡å»è¡¨å¤´ï¼‰
                    papers = len(re.findall(r'\|.*?\|.*?\|.*?\|.*?\|.*?\|', content)) - 1
                    # è®¡ç®—æœ‰ä»£ç å®ç°çš„è®ºæ–‡æ•°é‡
                    codes = len(re.findall(r'\[\[(?!âš ï¸).*?\]\]', content))
                    total_papers += papers
                    total_codes += codes

        # è¯»å–ç°æœ‰çš„è‹±æ–‡READMEå†…å®¹
        with open("README.md", "r", encoding="utf-8") as f:
            content = f.read()

        # åªæ›´æ–°ç»Ÿè®¡ä¿¡æ¯éƒ¨åˆ†
        new_content = re.sub(
            r'## Statistics\n\n- Total Papers: \d+\n- Code Implementations: \d+',
            f'## Statistics\n\n- Total Papers: {total_papers}\n- Code Implementations: {total_codes}',
            content
        )

        # å†™å…¥æ›´æ–°åçš„å†…å®¹
        with open("README.md", "w", encoding="utf-8") as f:
            f.write(new_content)

        # è¯»å–ç°æœ‰çš„ä¸­æ–‡READMEå†…å®¹
        with open("README_CN.md", "r", encoding="utf-8") as f:
            content = f.read()

        # åªæ›´æ–°ç»Ÿè®¡ä¿¡æ¯éƒ¨åˆ†
        new_content = re.sub(
            r'## ğŸ“Šç»Ÿè®¡\n\n- è®ºæ–‡æ€»æ•°ï¼š\d+ç¯‡\n- ä»£ç å®ç°ï¼š\d+ä¸ª',
            f'## ğŸ“Šç»Ÿè®¡\n\n- è®ºæ–‡æ€»æ•°ï¼š{total_papers}ç¯‡\n- ä»£ç å®ç°ï¼š{total_codes}ä¸ª',
            content
        )

        # å†™å…¥æ›´æ–°åçš„å†…å®¹
        with open("README_CN.md", "w", encoding="utf-8") as f:
            f.write(new_content)

    def run(self):
        """è¿è¡Œæ›´æ–°ç¨‹åº"""
        print("å¼€å§‹æ›´æ–°è®ºæ–‡åˆ—è¡¨...")

        for category, query in self.keywords.items():
            print(f"\nå¤„ç†åˆ†ç±»: {category}")
            print(f"ä½¿ç”¨æŸ¥è¯¢: {query}")
            papers = self.get_daily_papers(category, query)
            if papers:
                print(f"æ‰¾åˆ° {len(papers)} ç¯‡æ–°è®ºæ–‡")
                self.update_category_readme(category, papers)
            else:
                print("æ²¡æœ‰æ‰¾åˆ°æ–°è®ºæ–‡")

        self.update_root_readme()
        print("\næ›´æ–°å®Œæˆï¼")

if __name__ == "__main__":
    updater = PaperUpdater()
    updater.run()